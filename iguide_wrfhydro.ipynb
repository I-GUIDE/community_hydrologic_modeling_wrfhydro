{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1233150b-c4ba-4057-9639-106d7ae36cd4",
   "metadata": {},
   "source": [
    "<img src=\"statics/iguide_logo.png\" width=200 height=200 />\n",
    "\n",
    "# National Water Model (WRF-Hydro) on I-GUIDE Platform for Scalable Modeling of Hydroclimatic Extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f609a77-8dc4-4865-bf9c-f89a8847a309",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> Note: Some cells require User Interaction; \"Run cell-by-cell\" is recommended; \"Run All\" will not work. </h4>\n",
    "\n",
    "As a use case to support and drive the development of scalable modeling of hydroclimatic extremes, a workflow system for setting up and executing subsets of the [National Water Model (NWM)](https://water.noaa.gov/about/nwm) has been prototyped. The NWM is an implementation of the [Weather Research and Forecasting Model Hydrological modeling system (WRF-Hydro)](https://ral.ucar.edu/projects/wrf_hydro) at the US continental scale. The cyberinfrastructure and workflows needed to set up and configure the data product subsets for a modeling domain of interest are complex, and demand a high level of skill from researchers, thus limiting broad applicability. [I-GUIDE](https://iguide.illinois.edu/) is building on modeling capabilities developed by the [HydroShare](https://www.hydroshare.org/) and [CyberGIS-Compute](https://cybergisxhub.cigi.illinois.edu/knowledge-base/components/cybergis-compute/what-is-cybergis-compute/) projects enabling scalable computing for the research community and integrating data connectors and processors from the [GeoEDF](https://github.com/geoedf) project to deploy easy to use workflows for setting up and running WRF-Hydro configured like the NWM for any watershed specified in the NWM modeling domain. The goal is to make it easy for researchers to identify or select a watershed of interest, set up the inputs for WRF-Hydro configured equivalently to the NWM and run the model to reproduce NWM results. This then serves as a starting point for in-depth evaluation of NWM results in the watershed of interest and research to improve understanding and modeling of the hydrological processes in that watershed that could be fed back into the NWM. It also serves as a starting point for broader collaborations connecting with social and environmental research, one example being the geospatial aspects of perspectives from river-related organizations elicited through surveys and interviews. Our work serves as a prototype of a general methodology enabled by the I-GUIDE Platform that broadens participation in modeling by reducing the needs for software installation and configuration, enabling easy access to high-performance computing, and supporting reproducibility and interoperability. The use of the I-GUIDE Platform that combines cloud and high-performance computing enables scaling up of this modeling workflow to more complex and larger domains than what researchers could address with their own personal computing resources.\n",
    "\n",
    "<center><img src=\"statics/wrfhydro_flow.png\" width=600 height=400 /></center>\n",
    "\n",
    "A typical WRF-Hydro model run is composed of 4 essential elements as shown below: model configurations, domain data, forcing data and model execution. I-GUIDE platform takes care of the last three element as much as possible and enables users to focus on the model configurations to explore scientific questions of interest. The diagram below shows the setup for a typical WRF-Hydro model on I-GUIDE platform.\n",
    "\n",
    "<center><img src=\"statics/wrfhydro.png\" width=800 height=600 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f009be-88f9-4518-804d-e4f94a11652d",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "\n",
    "This map layout represents the Logan River Watershed in Utah. For this example, we have selected the upstream watershed (the highlighted one).\n",
    "\n",
    "<center><img src=\"statics//Layout.jpg\" width=400 height=300 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55b5ca",
   "metadata": {},
   "source": [
    "## Setup Simulation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84cb70-fe88-4301-a794-2300f2756c1a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Import all libraries needed to run this Jupyter notebook</b> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e4c27-7e8e-40a4-b5e6-d80b51380230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # allows us to communicate with the operating system\n",
    "import time # this module provides various time-related functions\n",
    "from datetime import datetime, timedelta # to specify the time domain for analysis\n",
    "import shutil # this module offers a number of high-level operations on files and collections of files\n",
    "import requests # request module lets us make request to web pages\n",
    "import xarray as xr #xarray makes it easier to work with multidimensional datasets like the NWM forecasts.\n",
    "import matplotlib.pyplot as plt  # helps to create plots.\n",
    "from IPython.display import display, HTML # for display warnings\n",
    "import matplotlib.pyplot as plt # for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7fa12-94ea-4f5c-9ffb-d62d2b377e87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Specify the spatial and time domains as well as the WRF-Hydro version </b> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ba18c-da13-4d76-9c6e-4c9c39f060ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huc12 id\n",
    "huc12 = \"160102030302\"  # huc 12 to identify the spatial domain of interest\n",
    "\n",
    "# Start at 00:00 (12AM)\n",
    "start_datetime = datetime(2016, 1, 1)     # specify the simulation start time  (Year, Month, Day)\n",
    "#                          Y   M   D\n",
    "# End at 00:00 (12AM)\n",
    "end_datetime = datetime(2016, 1, 7)     # specify the simulation end time  (Year, Month, Day)\n",
    "#                        Y   M   D\n",
    "\n",
    "# version WRFHydro codebase on github (tag/release/commit_id)\n",
    "wrfhydro_version = \"v5.2.0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc2b1c-a3ba-438c-9780-fe82d180e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_subset_domain = {\"huc12_id\": huc12, \n",
    "                        \"start_date\": start_datetime.strftime(\"%m/%d/%Y\"), \n",
    "                        \"end_date\": end_datetime.strftime(\"%m/%d/%Y\")}\n",
    "params_subset_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293edf59-fa23-4835-82ab-f7fe71e7d974",
   "metadata": {},
   "source": [
    "## Subset DOMAIN Files with GeoEDF Data Connector on CyberGIS-Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cebe0-f046-4fc9-b7bc-169866211e6d",
   "metadata": {},
   "source": [
    "The source of WRFHydro DOMAIN files is [CUAHSI Domain Subsetter](https://subset.cuahsi.org/) service. I-GUIDE provides a reusable [GeoEDF Data Connector](https://dl.acm.org/doi/10.1145/3311790.3396631) ([CUAHSISubsetterInput-Connector](https://github.com/I-GUIDE/cybergis-compute-cuahsisubsetterinput-connector) ) that makes requests to CUAHSI Domain Subsetter REST APIs and retrieves the domain files ready for model use. The GeoEDF Data Connector has been integrated into [CyberGIS-Compute](https://cybergis.github.io/cybergis-compute-python-sdk/reference.html) as a job that can be invoked by users from Jupyter environment and executed on supported HPC resources. The subset domain files staged remotely is ready for use by WRFHydro model on HPC, and user has the option to download the files from HPC back to Jupyter for local manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba36e6-bc0d-4417-94f4-4045d6961a92",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the cell below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (5-8 mins)\n",
    "- Switch to \"Download Job Result\" tabpage\n",
    "- Choose \"/\" and click on Download\n",
    "- Wait until downloading is finished\n",
    "- Proceed to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cybergis_compute_client\n",
    "from cybergis_compute_client import CyberGISCompute\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.show_ui(defaultJob=\"CUAHSI_Subsetter_Connector\", input_params=params_subset_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59de121-8b4e-49c9-94fc-2b07c284b43d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> NOTE: </b> Before running the next cell click on the download tab above <b> \"Download Job Result\" </b> and <b> \"Download\" </b> the outputs using <b> \"/\" </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a78851-c2bc-4d88-ba8e-17b7844aa9d7",
   "metadata": {},
   "source": [
    "Retain Domain Subsetter JobID for later reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobid_cuahsi_subset_domain = cybergis.job.id\n",
    "jobid_cuahsi_subset_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcb9a2-32ec-4903-b1ce-162e16029806",
   "metadata": {},
   "source": [
    "Ensure results have been downloaded for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd50dd-be7a-4548-9a01-c221492fa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_output = cybergis.recentDownloadPath\n",
    "domain_output\n",
    "if not os.path.isfile(os.path.join(domain_output, \"Route_Link.nc\")):\n",
    "    display(HTML('<h4 style=\"color:red;\">It appears you did not download the job results per instruction above, please double check!</h4>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa001f-30c0-4a01-80c0-ecbc4b4c7ede",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set up parameters for the next job in the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0eccba-1fc4-4ef4-8312-f5a2cdbe9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_subset_forcing = {\"Domain_Path\": jobid_cuahsi_subset_domain, \n",
    "                        \"start_date\": start_datetime.strftime(\"%m/%d/%Y\"), \n",
    "                        \"end_date\": end_datetime.strftime(\"%m/%d/%Y\")}\n",
    "params_subset_forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e2c4f-c6c7-44e4-a918-09ccd1960316",
   "metadata": {},
   "source": [
    "## Subset FORCINGS with GeoEDF Data Processor on CyberGIS-Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f1265-fefd-4163-8e24-5964eefa6282",
   "metadata": {},
   "source": [
    "The source of WRF-Hydro FORCING files is [AORC](https://registry.opendata.aws/nwm-archive/) dataset hosted on AWS. I-GUIDE provides a reusable [GeoEDF Data Processor](https://dl.acm.org/doi/10.1145/3311790.3396631) ([SubsetForcingData-Processor](https://github.com/I-GUIDE/cybergis-compute-subsetaorcforcingdata-processor) ) that subsets forcing files spatially and temporally. This GeoEDF Data Processor has been integrated into [CyberGIS-Compute](https://cybergis.github.io/cybergis-compute-python-sdk/reference.html) as a job that can be invoked by users from Jupyter environment and executed on supported HPC resources. The subset forcing files staged remotely is ready for use by WRFHydro model on HPC, and user has the option to download the files from HPC back to Jupyter for local manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b10d6-3ad5-4648-930d-02fe138fe83b",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the cell below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (2-4 mins)\n",
    "- Proceed to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd3436-1624-4fcb-a02c-4f5554acacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cybergis_compute_client\n",
    "from cybergis_compute_client import CyberGISCompute\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.show_ui(defaultJob=\"Subset_AORC_Forcing_Data_Processor\", input_params=params_subset_forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca565355-50c7-4688-9a0e-4442d6269571",
   "metadata": {},
   "source": [
    "Retain Forcing Processor JobID for later reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f50725-0878-4e41-bd84-1d1669c705d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobid_subset_forcing = cybergis.job.id\n",
    "jobid_subset_forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c202e-dfe2-4898-aed2-19b50c3a4a6b",
   "metadata": {},
   "source": [
    "## Prepare Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2713c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Simulation\" directory\n",
    "workspace = os.getcwd()\n",
    "simulation_dir = os.path.join(workspace, 'Simulation')\n",
    "if os.path.exists(simulation_dir):\n",
    "    shutil.rmtree(simulation_dir)\n",
    "os.makedirs(simulation_dir)\n",
    "#List of files\n",
    "os.listdir(simulation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3486717-1af3-430e-9f26-7273ab6aefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/NCAR/wrf_hydro_nwm_public/v5.2.0/trunk/NDHMS/template/setEnvar.sh\n",
    "! sed -i '/export HYDRO_D=0/c\\export HYDRO_D=1' ./setEnvar.sh\n",
    "! sed -i '/export SPATIAL_SOIL=0/c\\export SPATIAL_SOIL=1' ./setEnvar.sh\n",
    "! cat ./setEnvar.sh | grep -E 'HYDRO_D|SPATIAL_SOIL'\n",
    "! mv ./setEnvar.sh {simulation_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56f547-b5ac-4c11-9ee5-1f32bee122df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# namelist.hrldas --> START_YEAR START_MONTH START_DAY START_HOUR START_MIN RESTART_FILENAME_REQUESTED\n",
    "start_year = start_datetime.year\n",
    "start_month = \"{:02d}\".format(start_datetime.month)\n",
    "start_day = \"{:02d}\".format(start_datetime.day)\n",
    "start_hour = \"{:02d}\".format(start_datetime.hour)\n",
    "start_minute = \"{:02d}\".format(start_datetime.minute)\n",
    "khour = (end_datetime - start_datetime) / timedelta(hours=1)\n",
    "khour = \"{}\".format(int(khour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f2e74-73c3-4a05-b07a-aae0fa55a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf namelist.hrldas\n",
    "! wget https://raw.githubusercontent.com/NCAR/wrf_hydro_nwm_public/v5.2.0/trunk/NDHMS/template/NoahMP/namelist.hrldas\n",
    "! sed -i  '/HRLDAS_SETUP_FILE/c\\HRLDAS_SETUP_FILE = \"./DOMAIN/wrfinput_d0x.nc\"' ./namelist.hrldas\n",
    "! sed -i  '/START_YEAR/c\\START_YEAR = '\"$start_year\" ./namelist.hrldas\n",
    "! sed -i  '/START_MONTH/c\\START_MONTH = '\"$start_month\" ./namelist.hrldas\n",
    "! sed -i  '/START_DAY/c\\START_DAY = '\"$start_day\" ./namelist.hrldas\n",
    "! sed -i  '/START_HOUR/c\\START_HOUR = '\"$start_hour\" ./namelist.hrldas\n",
    "! sed -i  '/START_MIN/c\\START_MIN = '\"$start_minute\" ./namelist.hrldas\n",
    "! sed -i  '/KHOUR =/c\\KHOUR = '\"$khour\" ./namelist.hrldas\n",
    "! sed -i  '/RESTART_FILENAME_REQUESTED/c\\!RESTART_FILENAME_REQUESTED = \"\"' ./namelist.hrldas\n",
    "! grep -E 'HRLDAS_SETUP_FILE|START_|KHOUR' ./namelist.hrldas\n",
    "! mv ./namelist.hrldas {simulation_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1dbbb-bec1-4dfa-85ad-f5471ee7c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydro.namelist  --> RESTART_FILE\n",
    "! rm -rf hydro.namelist\n",
    "! wget https://raw.githubusercontent.com/NCAR/wrf_hydro_nwm_public/v5.2.0/trunk/NDHMS/template/HYDRO/hydro.namelist\n",
    "! sed -i '/GEO_STATIC_FLNM/c\\GEO_STATIC_FLNM = \"./DOMAIN/geo_em.d0x.nc\"' ./hydro.namelist\n",
    "! sed -i '/RESTART_FILE/c\\!RESTART_FILE = \"\"' ./hydro.namelist\n",
    "! sed -i  '/GW_RESTART/c\\GW_RESTART = 0' ./hydro.namelist\n",
    "! sed -i  '/LSMOUT_DOMAIN/c\\LSMOUT_DOMAIN = 1' ./hydro.namelist\n",
    "! sed -i  '/output_gw/c\\output_gw = 1' ./hydro.namelist\n",
    "! sed -i '/outlake/c\\outlake  = 0' ./hydro.namelist\n",
    "! sed -i '/output_gw/c\\output_gw  = 0' ./hydro.namelist\n",
    "! sed -i '/GWBASESWCRT/c\\GWBASESWCRT  = 1' ./hydro.namelist\n",
    "! sed -i '/output_channelBucket_influx/c\\output_channelBucket_influx  = 2' ./hydro.namelist\n",
    "! sed -i '/channel_option/c\\channel_option  = 2' ./hydro.namelist\n",
    "! sed -i '/route_link_f/c\\route_link_f  = \"./DOMAIN/Route_Link.nc\"' ./hydro.namelist\n",
    "! sed -i '/compound_channel/c\\!compound_channel  = .FALSE.' ./hydro.namelist\n",
    "! sed -i '/route_lake_f/c\\!route_lake_f  = \"./DOMAIN/LAKEPARM.nc\"' ./hydro.namelist\n",
    "! sed -i '/gwbasmskfil/c\\!gwbasmskfil  = \"./DOMAIN/GWBASINS.nc\"' ./hydro.namelist\n",
    "! sed -i '/UDMP_OPT/c\\UDMP_OPT  = 1' ./hydro.namelist\n",
    "! sed -i '/!udmap_file/c\\udmap_file = \"./DOMAIN/spatialweights.nc\"' ./hydro.namelist\n",
    "! grep -E \"RESTART|outlake|GWBASESWCRT|route_lake_f|gwbasmskfil\" ./hydro.namelist\n",
    "! mv ./hydro.namelist {simulation_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d116bc-dfa3-41fe-ac3c-b42d0d3799cc",
   "metadata": {},
   "source": [
    "## Run WRFHydro Model on HPC with CyberGIS-Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa142b-3cf8-4916-afb3-1212ac439f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_wrfhydro = {\"Model_Version\": wrfhydro_version,\n",
    "                   \"LSM_Type\": \"NoahMP\",\n",
    "                   \"Forcing_Path\": jobid_subset_forcing,\n",
    "                   \"Domain_Path\": jobid_cuahsi_subset_domain,\n",
    "                   \"Merge_Output\": \"True\"}\n",
    "params_wrfhydro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c2ec8-1c60-424f-9ec6-226c9600f3b5",
   "metadata": {},
   "source": [
    "<h4 style=\"color:red;\"> User Interaction Required </h4>\n",
    "\n",
    "- Run the cell below \n",
    "- Click on \"Submit Job\" on the \"Your Job Status\" tabpage \n",
    "- Wait until Job is finished (3-5 mins)\n",
    "- Switch to \"Download Job Result\" tabpage\n",
    "- Choose \"Outputs_Merged/CHRTOUT\" and click on Download\n",
    "- Wait unitl downloading is finished\n",
    "- Proceed to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a5878-22b2-4fe3-adc0-ec5147ddf0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cybergis_compute_client\n",
    "from cybergis_compute_client import CyberGISCompute\n",
    "\n",
    "cybergis = CyberGISCompute(url=\"cgjobsup.cigi.illinois.edu\", isJupyter=True, protocol=\"HTTPS\", port=443, suffix=\"v2\")\n",
    "cybergis.create_job_by_ui(defaultJob=\"wrfhydro-5.x\", defaultDataFolder=simulation_dir,input_params=params_wrfhydro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648ae72-6e50-4416-9905-b548c8a24ef8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> NOTE: </b> Before running the next cell click on the download tab above <b> \"Download Job Result\" </b> and <b> \"Download\" </b> the <b> \"Outputs_Merged/CHRTOUT\" </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453da88-f434-44cf-bbed-1243dfc94e40",
   "metadata": {},
   "source": [
    "Retain WRF-Hydro JobID for later reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e9e39-1117-4681-9d7b-4fbb32511dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobid_wrfhydro = cybergis.job.id\n",
    "output_wrfhydro = cybergis.recentDownloadPath\n",
    "!ls -LR {output_wrfhydro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75070bf3-422a-4f6b-b150-9be334a648b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(os.path.join(output_wrfhydro, \"CHRTOUT_DOMAIN1_merged.nc\")):\n",
    "    display(HTML('<h4 style=\"color:red;\">It appears you did not download the job results per instruction above, please double check!</h4>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa8334-87b1-45a4-865b-355b08819087",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0dec5-95f4-40eb-8325-0de6d274d4e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path of the merged file of channel routing \"CHRTOUT_DOMAIN1_merged.nc\"\n",
    "ch_file = '{}/CHRTOUT_DOMAIN1_merged.nc'.format(output_wrfhydro)\n",
    "print(ch_file)\n",
    "# path of the route link \"Rouet_Link.nc\"\n",
    "routelink ='/home/jovyan/globus_download_{}/Route_Link.nc'.format(jobid_cuahsi_subset_domain)\n",
    "print(routelink)\n",
    "\n",
    "# convert rouetlink to dataframe\n",
    "route_df = xr.open_dataset(routelink).to_dataframe() # convert routelink to dataframe\n",
    "route_df.gages = route_df.gages.str.decode('utf-8').str.strip()\n",
    "route_df # print out the routelink dataframe\n",
    "\n",
    "# Re-name the \"Route_Link.nc\" variables\n",
    "cols = ['order', 'link', 'gages', 'lat', 'lon', 'to', 'from']  # columns name of original routelink dataframe\n",
    "route_re_df = route_df[cols].sort_values(by=['order'])      # reduce the size of routelink dataframe to include only these columns ['order', 'link', 'gages', 'lat', 'lon', 'to', 'from']\n",
    "\n",
    "# rename the columns\n",
    "route_renm_df = route_re_df.rename(index=str, columns={\"order\": \"stream_order\",\n",
    "                                       \"link\": \"comid\",\n",
    "                                       \"from\": 'upstream_comid',\n",
    "                                       'to':'downstream_comid',\n",
    "                                       \"gages\": 'usgs_gageid',\n",
    "                                       \"lat\": 'lat-midpoint',\n",
    "                                       \"lon\": 'lon-midpoint'})\n",
    "route_renm_df.reset_index(inplace=True)\n",
    "# data.drop('linkDim', axis=1, inplace=True)\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "# Load channel routing data \"CHRTOUT_DOMAIN1_merged.nc\"\n",
    "channel_ds = xr.open_dataset(ch_file)\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "# Reduce the size of the dataset to only the essential variables.\n",
    "reach_ds = channel_ds\n",
    "reach_ds = reach_ds[['streamflow',        # Streamflow \n",
    "                     'q_lateral',         # lateral inflow through reach\n",
    "                     'qSfcLatRunoff',     # runoff from terrain routing\n",
    "                     'qBucket',           # flux from groundwater (gw) bucket\n",
    "                     'qBtmVertRunoff',    # runoff from bottom of soil to bucket\n",
    "                     'order',\n",
    "                     'velocity',\n",
    "                     'Head',\n",
    "                     'elevation']]\n",
    "\n",
    "## clean unnecessary data\n",
    "reach_ds = reach_ds.reset_coords()\n",
    "reach_ds = reach_ds.drop(labels=['latitude','longitude'])\n",
    "reach_ds.attrs = {}\n",
    "\n",
    "route_renm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53930b64-d736-4740-a83b-f4bc20cfb71d",
   "metadata": {},
   "source": [
    "#### Plot hydrograph for a reach within the watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65431c4d-c45c-42fe-bd62-9607f128fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reachid= 664168\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,6), sharex='col')\n",
    "\n",
    "reach_ds.sel(feature_id=reachid)['streamflow'].plot(ax=ax,\n",
    "                                                    label='Total Outflow ($m^3$/s)',\n",
    "                                                    color='red',\n",
    "                                                    linestyle='--')\n",
    "# plot settings\n",
    "plt.ylabel('Discharge, $m^3$/s')\n",
    "plt.xlabel(\"Time\")\n",
    "# plt.title(\"\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('Hydrograph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9934d21-d924-4870-8a23-2a02d38ab16f",
   "metadata": {},
   "source": [
    "#### Plot hydrograph for all reaches (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a92542-8d94-4f01-8dfe-2ba874e4746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the codes below to plot hydrograph for all reaches\n",
    "## plot hydrograph for all reaches within the spatail domain \n",
    "\n",
    "# for r in route_renm_df['comid']:\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(12,6), sharex='col')\n",
    "#     reach_ds.sel(feature_id=r)['streamflow'].plot(ax=ax,\n",
    "#                                                         label='Total Outflow ($m^3$/s)',\n",
    "#                                                         color='red',\n",
    "#                                                         linestyle='--')\n",
    "#     # plot settings\n",
    "#     plt.ylabel('Discharge, $m^3$/s')\n",
    "#     plt.xlabel(\"Time\")\n",
    "#     # plt.title(\"\")\n",
    "#     plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f801f-4dce-4e18-a725-2dd3ee44341b",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iguide]",
   "language": "python",
   "name": "conda-env-iguide-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
